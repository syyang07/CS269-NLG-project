{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "So, since the UDF approach wasn't fruitful, we will use Stanford's PTBTokenizer.\n",
    "\n",
    "Downloading either CoreNLP or the stanford-parser is required https://stanfordnlp.github.io/CoreNLP/\n",
    "\n",
    "PySpark creates multiple .txt files when writing the examples. The PTBTokenizer is able to tokenize multiple files by reading a master file, so let's create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls reviews.txt/*.txt > reviews.txt/files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews.txt/part-00000-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00001-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00002-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00003-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00004-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00005-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00006-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00007-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00008-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00009-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00010-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00011-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00012-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00013-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00014-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00015-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00016-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00017-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00018-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00019-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00020-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00021-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00022-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00023-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00024-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00025-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00026-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00027-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00028-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00029-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00030-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00031-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00032-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00033-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00034-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00035-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00036-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00037-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00038-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n",
      "reviews.txt/part-00039-966fba6e-045e-4c06-a8d1-3cfcf2b05122-c000.txt\r\n"
     ]
    }
   ],
   "source": [
    "!cat reviews.txt/files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls context.txt/*.txt > context.txt/files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context.txt/part-00000-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00001-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00002-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00003-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00004-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00005-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00006-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00007-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00008-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00009-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00010-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00011-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00012-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00013-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00014-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00015-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00016-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00017-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00018-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00019-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00020-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00021-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00022-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00023-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00024-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00025-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00026-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00027-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00028-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00029-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00030-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00031-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00032-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00033-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00034-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00035-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00036-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00037-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00038-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n",
      "context.txt/part-00039-54ef3ba7-11a7-46a9-8753-2ebf585f3ac4-c000.txt\r\n"
     ]
    }
   ],
   "source": [
    "!cat context.txt/files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 860417521 tokens at 5828586.78 tokens per second.\r\n"
     ]
    }
   ],
   "source": [
    "!CLASSPATH=~/dev/stanford-parser-full-2018-10-17/stanford-parser.jar java edu.stanford.nlp.process.PTBTokenizer -lowerCase -preserveLines -fileList reviews.txt/files.txt > tokenized_reviews.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 103243240 tokens at 5441268.38 tokens per second.\r\n"
     ]
    }
   ],
   "source": [
    "!CLASSPATH=~/dev/stanford-parser-full-2018-10-17/stanford-parser.jar java edu.stanford.nlp.process.PTBTokenizer -lowerCase -preserveLines -fileList context.txt/files.txt > tokenized_context.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the line counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6683763\r\n"
     ]
    }
   ],
   "source": [
    "!cat tokenized_reviews.txt | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6683763\r\n"
     ]
    }
   ],
   "source": [
    "!cat tokenized_context.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to split these files into a train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./split.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a training data set with 6 million examples, on top of that we have a validation data set with 15k examples. We can use the remaining data for testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
